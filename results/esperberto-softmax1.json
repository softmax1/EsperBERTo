{
    "trainer_log": [
        {
            "loss": 9.0905,
            "learning_rate": 4.999982511306441e-05,
            "epoch": 0.0,
            "step": 1
        },
        {
            "loss": 8.0095,
            "learning_rate": 4.9825113064403866e-05,
            "epoch": 0.0,
            "step": 1000
        },
        {
            "loss": 7.6096,
            "learning_rate": 4.965022612880773e-05,
            "epoch": 0.01,
            "step": 2000
        },
        {
            "loss": 7.3624,
            "learning_rate": 4.947533919321159e-05,
            "epoch": 0.01,
            "step": 3000
        },
        {
            "loss": 7.2449,
            "learning_rate": 4.930045225761545e-05,
            "epoch": 0.01,
            "step": 4000
        },
        {
            "loss": 7.0597,
            "learning_rate": 4.912556532201932e-05,
            "epoch": 0.02,
            "step": 5000
        },
        {
            "loss": 6.9601,
            "learning_rate": 4.8950678386423185e-05,
            "epoch": 0.02,
            "step": 6000
        },
        {
            "loss": 6.8153,
            "learning_rate": 4.877579145082704e-05,
            "epoch": 0.02,
            "step": 7000
        },
        {
            "loss": 6.6753,
            "learning_rate": 4.8600904515230906e-05,
            "epoch": 0.03,
            "step": 8000
        },
        {
            "loss": 6.5139,
            "learning_rate": 4.842601757963477e-05,
            "epoch": 0.03,
            "step": 9000
        },
        {
            "loss": 6.4249,
            "learning_rate": 4.825113064403863e-05,
            "epoch": 0.03,
            "step": 10000
        },
        {
            "loss": 6.3509,
            "learning_rate": 4.807624370844249e-05,
            "epoch": 0.04,
            "step": 11000
        },
        {
            "loss": 6.2269,
            "learning_rate": 4.7901356772846354e-05,
            "epoch": 0.04,
            "step": 12000
        },
        {
            "loss": 6.1468,
            "learning_rate": 4.772646983725022e-05,
            "epoch": 0.05,
            "step": 13000
        },
        {
            "loss": 6.1358,
            "learning_rate": 4.755158290165408e-05,
            "epoch": 0.05,
            "step": 14000
        },
        {
            "loss": 6.019,
            "learning_rate": 4.7376695966057945e-05,
            "epoch": 0.05,
            "step": 15000
        },
        {
            "loss": 5.9563,
            "learning_rate": 4.720180903046181e-05,
            "epoch": 0.06,
            "step": 16000
        },
        {
            "loss": 5.9469,
            "learning_rate": 4.702692209486567e-05,
            "epoch": 0.06,
            "step": 17000
        },
        {
            "loss": 5.8852,
            "learning_rate": 4.685203515926954e-05,
            "epoch": 0.06,
            "step": 18000
        },
        {
            "loss": 5.8321,
            "learning_rate": 4.6677148223673394e-05,
            "epoch": 0.07,
            "step": 19000
        },
        {
            "loss": 5.7713,
            "learning_rate": 4.650226128807726e-05,
            "epoch": 0.07,
            "step": 20000
        },
        {
            "loss": 5.746,
            "learning_rate": 4.632737435248112e-05,
            "epoch": 0.07,
            "step": 21000
        },
        {
            "loss": 5.6905,
            "learning_rate": 4.6152487416884985e-05,
            "epoch": 0.08,
            "step": 22000
        },
        {
            "loss": 5.6406,
            "learning_rate": 4.597760048128885e-05,
            "epoch": 0.08,
            "step": 23000
        },
        {
            "loss": 5.5923,
            "learning_rate": 4.580271354569271e-05,
            "epoch": 0.08,
            "step": 24000
        },
        {
            "loss": 5.5964,
            "learning_rate": 4.5627826610096576e-05,
            "epoch": 0.09,
            "step": 25000
        },
        {
            "loss": 5.5325,
            "learning_rate": 4.545293967450044e-05,
            "epoch": 0.09,
            "step": 26000
        },
        {
            "loss": 5.4921,
            "learning_rate": 4.5278052738904304e-05,
            "epoch": 0.09,
            "step": 27000
        },
        {
            "loss": 5.4603,
            "learning_rate": 4.510316580330816e-05,
            "epoch": 0.1,
            "step": 28000
        },
        {
            "loss": 5.4678,
            "learning_rate": 4.4928278867712025e-05,
            "epoch": 0.1,
            "step": 29000
        },
        {
            "loss": 5.4118,
            "learning_rate": 4.475339193211589e-05,
            "epoch": 0.1,
            "step": 30000
        },
        {
            "loss": 5.3463,
            "learning_rate": 4.457850499651975e-05,
            "epoch": 0.11,
            "step": 31000
        },
        {
            "loss": 5.3394,
            "learning_rate": 4.4403618060923616e-05,
            "epoch": 0.11,
            "step": 32000
        },
        {
            "loss": 5.345,
            "learning_rate": 4.422873112532748e-05,
            "epoch": 0.12,
            "step": 33000
        },
        {
            "loss": 5.3087,
            "learning_rate": 4.4053844189731344e-05,
            "epoch": 0.12,
            "step": 34000
        },
        {
            "loss": 5.293,
            "learning_rate": 4.387895725413521e-05,
            "epoch": 0.12,
            "step": 35000
        },
        {
            "loss": 5.2013,
            "learning_rate": 4.3704070318539064e-05,
            "epoch": 0.13,
            "step": 36000
        },
        {
            "loss": 5.2245,
            "learning_rate": 4.352918338294293e-05,
            "epoch": 0.13,
            "step": 37000
        },
        {
            "loss": 5.2189,
            "learning_rate": 4.335429644734679e-05,
            "epoch": 0.13,
            "step": 38000
        },
        {
            "loss": 5.1864,
            "learning_rate": 4.3179409511750656e-05,
            "epoch": 0.14,
            "step": 39000
        },
        {
            "loss": 5.1459,
            "learning_rate": 4.300452257615451e-05,
            "epoch": 0.14,
            "step": 40000
        },
        {
            "loss": 5.1332,
            "learning_rate": 4.282963564055838e-05,
            "epoch": 0.14,
            "step": 41000
        },
        {
            "loss": 5.1142,
            "learning_rate": 4.265474870496225e-05,
            "epoch": 0.15,
            "step": 42000
        },
        {
            "loss": 5.0963,
            "learning_rate": 4.247986176936611e-05,
            "epoch": 0.15,
            "step": 43000
        },
        {
            "loss": 5.0684,
            "learning_rate": 4.2304974833769974e-05,
            "epoch": 0.15,
            "step": 44000
        },
        {
            "loss": 5.0428,
            "learning_rate": 4.213008789817383e-05,
            "epoch": 0.16,
            "step": 45000
        },
        {
            "loss": 5.0108,
            "learning_rate": 4.1955200962577695e-05,
            "epoch": 0.16,
            "step": 46000
        },
        {
            "loss": 4.9946,
            "learning_rate": 4.178031402698156e-05,
            "epoch": 0.16,
            "step": 47000
        },
        {
            "loss": 4.9638,
            "learning_rate": 4.160542709138542e-05,
            "epoch": 0.17,
            "step": 48000
        },
        {
            "loss": 4.9858,
            "learning_rate": 4.143054015578928e-05,
            "epoch": 0.17,
            "step": 49000
        },
        {
            "loss": 4.9688,
            "learning_rate": 4.1255653220193144e-05,
            "epoch": 0.17,
            "step": 50000
        },
        {
            "loss": 4.9164,
            "learning_rate": 4.1080766284597014e-05,
            "epoch": 0.18,
            "step": 51000
        },
        {
            "loss": 4.938,
            "learning_rate": 4.090587934900088e-05,
            "epoch": 0.18,
            "step": 52000
        },
        {
            "loss": 4.9074,
            "learning_rate": 4.0730992413404735e-05,
            "epoch": 0.19,
            "step": 53000
        },
        {
            "loss": 4.8792,
            "learning_rate": 4.05561054778086e-05,
            "epoch": 0.19,
            "step": 54000
        },
        {
            "loss": 4.8842,
            "learning_rate": 4.038121854221246e-05,
            "epoch": 0.19,
            "step": 55000
        },
        {
            "loss": 4.8735,
            "learning_rate": 4.0206331606616326e-05,
            "epoch": 0.2,
            "step": 56000
        },
        {
            "loss": 4.8517,
            "learning_rate": 4.003144467102018e-05,
            "epoch": 0.2,
            "step": 57000
        },
        {
            "loss": 4.8394,
            "learning_rate": 3.985655773542405e-05,
            "epoch": 0.2,
            "step": 58000
        },
        {
            "loss": 4.8499,
            "learning_rate": 3.968167079982791e-05,
            "epoch": 0.21,
            "step": 59000
        },
        {
            "loss": 4.791,
            "learning_rate": 3.9506783864231774e-05,
            "epoch": 0.21,
            "step": 60000
        },
        {
            "loss": 4.8328,
            "learning_rate": 3.933189692863564e-05,
            "epoch": 0.21,
            "step": 61000
        },
        {
            "loss": 4.7851,
            "learning_rate": 3.91570099930395e-05,
            "epoch": 0.22,
            "step": 62000
        },
        {
            "loss": 4.7717,
            "learning_rate": 3.8982123057443366e-05,
            "epoch": 0.22,
            "step": 63000
        },
        {
            "loss": 4.7296,
            "learning_rate": 3.880723612184723e-05,
            "epoch": 0.22,
            "step": 64000
        },
        {
            "loss": 4.7431,
            "learning_rate": 3.8632349186251087e-05,
            "epoch": 0.23,
            "step": 65000
        },
        {
            "loss": 4.7293,
            "learning_rate": 3.845746225065495e-05,
            "epoch": 0.23,
            "step": 66000
        },
        {
            "loss": 4.7512,
            "learning_rate": 3.8282575315058814e-05,
            "epoch": 0.23,
            "step": 67000
        },
        {
            "loss": 4.7017,
            "learning_rate": 3.810768837946268e-05,
            "epoch": 0.24,
            "step": 68000
        },
        {
            "loss": 4.7114,
            "learning_rate": 3.793280144386654e-05,
            "epoch": 0.24,
            "step": 69000
        },
        {
            "loss": 4.6824,
            "learning_rate": 3.7757914508270405e-05,
            "epoch": 0.24,
            "step": 70000
        },
        {
            "loss": 4.6964,
            "learning_rate": 3.758302757267427e-05,
            "epoch": 0.25,
            "step": 71000
        },
        {
            "loss": 4.685,
            "learning_rate": 3.740814063707813e-05,
            "epoch": 0.25,
            "step": 72000
        },
        {
            "loss": 4.6731,
            "learning_rate": 3.7233253701482e-05,
            "epoch": 0.26,
            "step": 73000
        },
        {
            "loss": 4.6888,
            "learning_rate": 3.7058366765885854e-05,
            "epoch": 0.26,
            "step": 74000
        },
        {
            "loss": 4.636,
            "learning_rate": 3.688347983028972e-05,
            "epoch": 0.26,
            "step": 75000
        },
        {
            "loss": 4.6027,
            "learning_rate": 3.670859289469358e-05,
            "epoch": 0.27,
            "step": 76000
        },
        {
            "loss": 4.6158,
            "learning_rate": 3.6533705959097445e-05,
            "epoch": 0.27,
            "step": 77000
        },
        {
            "loss": 4.6077,
            "learning_rate": 3.635881902350131e-05,
            "epoch": 0.27,
            "step": 78000
        },
        {
            "loss": 4.5916,
            "learning_rate": 3.618393208790517e-05,
            "epoch": 0.28,
            "step": 79000
        },
        {
            "loss": 4.5819,
            "learning_rate": 3.6009045152309036e-05,
            "epoch": 0.28,
            "step": 80000
        },
        {
            "loss": 4.5827,
            "learning_rate": 3.58341582167129e-05,
            "epoch": 0.28,
            "step": 81000
        },
        {
            "loss": 4.5674,
            "learning_rate": 3.565927128111676e-05,
            "epoch": 0.29,
            "step": 82000
        },
        {
            "loss": 4.5596,
            "learning_rate": 3.548438434552062e-05,
            "epoch": 0.29,
            "step": 83000
        },
        {
            "loss": 4.5561,
            "learning_rate": 3.5309497409924485e-05,
            "epoch": 0.29,
            "step": 84000
        },
        {
            "loss": 4.5376,
            "learning_rate": 3.513461047432835e-05,
            "epoch": 0.3,
            "step": 85000
        },
        {
            "loss": 4.5312,
            "learning_rate": 3.4959723538732205e-05,
            "epoch": 0.3,
            "step": 86000
        },
        {
            "loss": 4.5331,
            "learning_rate": 3.4784836603136076e-05,
            "epoch": 0.3,
            "step": 87000
        },
        {
            "loss": 4.5243,
            "learning_rate": 3.460994966753994e-05,
            "epoch": 0.31,
            "step": 88000
        },
        {
            "loss": 4.5094,
            "learning_rate": 3.4435062731943804e-05,
            "epoch": 0.31,
            "step": 89000
        },
        {
            "loss": 4.497,
            "learning_rate": 3.426017579634767e-05,
            "epoch": 0.31,
            "step": 90000
        },
        {
            "loss": 4.5362,
            "learning_rate": 3.4085288860751524e-05,
            "epoch": 0.32,
            "step": 91000
        },
        {
            "loss": 4.477,
            "learning_rate": 3.391040192515539e-05,
            "epoch": 0.32,
            "step": 92000
        },
        {
            "loss": 4.4941,
            "learning_rate": 3.373551498955925e-05,
            "epoch": 0.33,
            "step": 93000
        },
        {
            "loss": 4.4936,
            "learning_rate": 3.3560628053963116e-05,
            "epoch": 0.33,
            "step": 94000
        },
        {
            "loss": 4.4822,
            "learning_rate": 3.338574111836697e-05,
            "epoch": 0.33,
            "step": 95000
        },
        {
            "loss": 4.454,
            "learning_rate": 3.3210854182770836e-05,
            "epoch": 0.34,
            "step": 96000
        },
        {
            "loss": 4.4291,
            "learning_rate": 3.303596724717471e-05,
            "epoch": 0.34,
            "step": 97000
        },
        {
            "loss": 4.4337,
            "learning_rate": 3.286108031157857e-05,
            "epoch": 0.34,
            "step": 98000
        },
        {
            "loss": 4.4615,
            "learning_rate": 3.268619337598243e-05,
            "epoch": 0.35,
            "step": 99000
        },
        {
            "loss": 4.4398,
            "learning_rate": 3.251130644038629e-05,
            "epoch": 0.35,
            "step": 100000
        },
        {
            "loss": 4.4307,
            "learning_rate": 3.2336419504790155e-05,
            "epoch": 0.35,
            "step": 101000
        },
        {
            "loss": 4.3981,
            "learning_rate": 3.216153256919402e-05,
            "epoch": 0.36,
            "step": 102000
        },
        {
            "loss": 4.4287,
            "learning_rate": 3.1986645633597876e-05,
            "epoch": 0.36,
            "step": 103000
        },
        {
            "loss": 4.3555,
            "learning_rate": 3.181175869800174e-05,
            "epoch": 0.36,
            "step": 104000
        },
        {
            "loss": 4.3981,
            "learning_rate": 3.1636871762405604e-05,
            "epoch": 0.37,
            "step": 105000
        },
        {
            "loss": 4.3904,
            "learning_rate": 3.1461984826809474e-05,
            "epoch": 0.37,
            "step": 106000
        },
        {
            "loss": 4.387,
            "learning_rate": 3.128709789121333e-05,
            "epoch": 0.37,
            "step": 107000
        },
        {
            "loss": 4.4087,
            "learning_rate": 3.1112210955617195e-05,
            "epoch": 0.38,
            "step": 108000
        },
        {
            "loss": 4.3989,
            "learning_rate": 3.093732402002106e-05,
            "epoch": 0.38,
            "step": 109000
        },
        {
            "loss": 4.3612,
            "learning_rate": 3.076243708442492e-05,
            "epoch": 0.38,
            "step": 110000
        },
        {
            "loss": 4.3588,
            "learning_rate": 3.0587550148828786e-05,
            "epoch": 0.39,
            "step": 111000
        },
        {
            "loss": 4.3477,
            "learning_rate": 3.0412663213232647e-05,
            "epoch": 0.39,
            "step": 112000
        },
        {
            "loss": 4.3357,
            "learning_rate": 3.023777627763651e-05,
            "epoch": 0.4,
            "step": 113000
        },
        {
            "loss": 4.3539,
            "learning_rate": 3.0062889342040374e-05,
            "epoch": 0.4,
            "step": 114000
        },
        {
            "loss": 4.3512,
            "learning_rate": 2.9888002406444238e-05,
            "epoch": 0.4,
            "step": 115000
        },
        {
            "loss": 4.3285,
            "learning_rate": 2.9713115470848095e-05,
            "epoch": 0.41,
            "step": 116000
        },
        {
            "loss": 4.3511,
            "learning_rate": 2.9538228535251962e-05,
            "epoch": 0.41,
            "step": 117000
        },
        {
            "loss": 4.2961,
            "learning_rate": 2.9363341599655826e-05,
            "epoch": 0.41,
            "step": 118000
        },
        {
            "loss": 4.2806,
            "learning_rate": 2.918845466405969e-05,
            "epoch": 0.42,
            "step": 119000
        },
        {
            "loss": 4.3004,
            "learning_rate": 2.9013567728463547e-05,
            "epoch": 0.42,
            "step": 120000
        },
        {
            "loss": 4.2857,
            "learning_rate": 2.883868079286741e-05,
            "epoch": 0.42,
            "step": 121000
        },
        {
            "loss": 4.2954,
            "learning_rate": 2.8663793857271278e-05,
            "epoch": 0.43,
            "step": 122000
        },
        {
            "loss": 4.2781,
            "learning_rate": 2.848890692167514e-05,
            "epoch": 0.43,
            "step": 123000
        },
        {
            "loss": 4.2841,
            "learning_rate": 2.8314019986078998e-05,
            "epoch": 0.43,
            "step": 124000
        },
        {
            "loss": 4.2566,
            "learning_rate": 2.8139133050482862e-05,
            "epoch": 0.44,
            "step": 125000
        },
        {
            "loss": 4.2665,
            "learning_rate": 2.7964246114886726e-05,
            "epoch": 0.44,
            "step": 126000
        },
        {
            "loss": 4.2519,
            "learning_rate": 2.7789359179290593e-05,
            "epoch": 0.44,
            "step": 127000
        },
        {
            "loss": 4.2435,
            "learning_rate": 2.761447224369445e-05,
            "epoch": 0.45,
            "step": 128000
        },
        {
            "loss": 4.2494,
            "learning_rate": 2.7439585308098314e-05,
            "epoch": 0.45,
            "step": 129000
        },
        {
            "loss": 4.2647,
            "learning_rate": 2.7264698372502178e-05,
            "epoch": 0.45,
            "step": 130000
        },
        {
            "loss": 4.251,
            "learning_rate": 2.708981143690604e-05,
            "epoch": 0.46,
            "step": 131000
        },
        {
            "loss": 4.2454,
            "learning_rate": 2.691492450130991e-05,
            "epoch": 0.46,
            "step": 132000
        },
        {
            "loss": 4.2353,
            "learning_rate": 2.6740037565713765e-05,
            "epoch": 0.47,
            "step": 133000
        },
        {
            "loss": 4.225,
            "learning_rate": 2.656515063011763e-05,
            "epoch": 0.47,
            "step": 134000
        },
        {
            "loss": 4.195,
            "learning_rate": 2.6390263694521493e-05,
            "epoch": 0.47,
            "step": 135000
        },
        {
            "loss": 4.2316,
            "learning_rate": 2.621537675892536e-05,
            "epoch": 0.48,
            "step": 136000
        },
        {
            "loss": 4.243,
            "learning_rate": 2.6040489823329217e-05,
            "epoch": 0.48,
            "step": 137000
        },
        {
            "loss": 4.2015,
            "learning_rate": 2.586560288773308e-05,
            "epoch": 0.48,
            "step": 138000
        },
        {
            "loss": 4.1878,
            "learning_rate": 2.5690715952136945e-05,
            "epoch": 0.49,
            "step": 139000
        },
        {
            "loss": 4.1885,
            "learning_rate": 2.551582901654081e-05,
            "epoch": 0.49,
            "step": 140000
        },
        {
            "loss": 4.1947,
            "learning_rate": 2.534094208094467e-05,
            "epoch": 0.49,
            "step": 141000
        },
        {
            "loss": 4.179,
            "learning_rate": 2.5166055145348533e-05,
            "epoch": 0.5,
            "step": 142000
        },
        {
            "loss": 4.1771,
            "learning_rate": 2.4991168209752396e-05,
            "epoch": 0.5,
            "step": 143000
        },
        {
            "loss": 4.1806,
            "learning_rate": 2.4816281274156257e-05,
            "epoch": 0.5,
            "step": 144000
        },
        {
            "loss": 4.1756,
            "learning_rate": 2.4641394338560124e-05,
            "epoch": 0.51,
            "step": 145000
        },
        {
            "loss": 4.1666,
            "learning_rate": 2.4466507402963984e-05,
            "epoch": 0.51,
            "step": 146000
        },
        {
            "loss": 4.1447,
            "learning_rate": 2.4291620467367848e-05,
            "epoch": 0.51,
            "step": 147000
        },
        {
            "loss": 4.1668,
            "learning_rate": 2.411673353177171e-05,
            "epoch": 0.52,
            "step": 148000
        },
        {
            "loss": 4.1535,
            "learning_rate": 2.3941846596175572e-05,
            "epoch": 0.52,
            "step": 149000
        },
        {
            "loss": 4.1472,
            "learning_rate": 2.3766959660579436e-05,
            "epoch": 0.52,
            "step": 150000
        },
        {
            "loss": 4.1481,
            "learning_rate": 2.35920727249833e-05,
            "epoch": 0.53,
            "step": 151000
        },
        {
            "loss": 4.1371,
            "learning_rate": 2.341718578938716e-05,
            "epoch": 0.53,
            "step": 152000
        },
        {
            "loss": 4.1534,
            "learning_rate": 2.3242298853791024e-05,
            "epoch": 0.54,
            "step": 153000
        },
        {
            "loss": 4.1471,
            "learning_rate": 2.306741191819489e-05,
            "epoch": 0.54,
            "step": 154000
        },
        {
            "loss": 4.1406,
            "learning_rate": 2.289252498259875e-05,
            "epoch": 0.54,
            "step": 155000
        },
        {
            "loss": 4.114,
            "learning_rate": 2.2717638047002615e-05,
            "epoch": 0.55,
            "step": 156000
        },
        {
            "loss": 4.1189,
            "learning_rate": 2.2542751111406476e-05,
            "epoch": 0.55,
            "step": 157000
        },
        {
            "loss": 4.0859,
            "learning_rate": 2.236786417581034e-05,
            "epoch": 0.55,
            "step": 158000
        },
        {
            "loss": 4.0931,
            "learning_rate": 2.2192977240214203e-05,
            "epoch": 0.56,
            "step": 159000
        },
        {
            "loss": 4.1135,
            "learning_rate": 2.2018090304618067e-05,
            "epoch": 0.56,
            "step": 160000
        },
        {
            "loss": 4.1432,
            "learning_rate": 2.1843203369021927e-05,
            "epoch": 0.56,
            "step": 161000
        },
        {
            "loss": 4.113,
            "learning_rate": 2.166831643342579e-05,
            "epoch": 0.57,
            "step": 162000
        },
        {
            "loss": 4.0634,
            "learning_rate": 2.1493429497829655e-05,
            "epoch": 0.57,
            "step": 163000
        },
        {
            "loss": 4.0624,
            "learning_rate": 2.131854256223352e-05,
            "epoch": 0.57,
            "step": 164000
        },
        {
            "loss": 4.0791,
            "learning_rate": 2.114365562663738e-05,
            "epoch": 0.58,
            "step": 165000
        },
        {
            "loss": 4.0656,
            "learning_rate": 2.0968768691041243e-05,
            "epoch": 0.58,
            "step": 166000
        },
        {
            "loss": 4.1005,
            "learning_rate": 2.0793881755445103e-05,
            "epoch": 0.58,
            "step": 167000
        },
        {
            "loss": 4.0845,
            "learning_rate": 2.061899481984897e-05,
            "epoch": 0.59,
            "step": 168000
        },
        {
            "loss": 4.0658,
            "learning_rate": 2.044410788425283e-05,
            "epoch": 0.59,
            "step": 169000
        },
        {
            "loss": 4.0586,
            "learning_rate": 2.0269220948656694e-05,
            "epoch": 0.59,
            "step": 170000
        },
        {
            "loss": 4.0695,
            "learning_rate": 2.0094334013060555e-05,
            "epoch": 0.6,
            "step": 171000
        },
        {
            "loss": 4.0772,
            "learning_rate": 1.9919447077464422e-05,
            "epoch": 0.6,
            "step": 172000
        },
        {
            "loss": 4.0216,
            "learning_rate": 1.9744560141868282e-05,
            "epoch": 0.61,
            "step": 173000
        },
        {
            "loss": 4.0401,
            "learning_rate": 1.9569673206272146e-05,
            "epoch": 0.61,
            "step": 174000
        },
        {
            "loss": 4.0302,
            "learning_rate": 1.9394786270676007e-05,
            "epoch": 0.61,
            "step": 175000
        },
        {
            "loss": 4.0897,
            "learning_rate": 1.921989933507987e-05,
            "epoch": 0.62,
            "step": 176000
        },
        {
            "loss": 4.0386,
            "learning_rate": 1.9045012399483738e-05,
            "epoch": 0.62,
            "step": 177000
        },
        {
            "loss": 4.0547,
            "learning_rate": 1.8870125463887598e-05,
            "epoch": 0.62,
            "step": 178000
        },
        {
            "loss": 4.0299,
            "learning_rate": 1.869523852829146e-05,
            "epoch": 0.63,
            "step": 179000
        },
        {
            "loss": 4.0217,
            "learning_rate": 1.8520351592695322e-05,
            "epoch": 0.63,
            "step": 180000
        },
        {
            "loss": 3.979,
            "learning_rate": 1.8345464657099186e-05,
            "epoch": 0.63,
            "step": 181000
        },
        {
            "loss": 4.0091,
            "learning_rate": 1.817057772150305e-05,
            "epoch": 0.64,
            "step": 182000
        },
        {
            "loss": 3.9869,
            "learning_rate": 1.7995690785906913e-05,
            "epoch": 0.64,
            "step": 183000
        },
        {
            "loss": 4.0013,
            "learning_rate": 1.7820803850310774e-05,
            "epoch": 0.64,
            "step": 184000
        },
        {
            "loss": 4.005,
            "learning_rate": 1.7645916914714638e-05,
            "epoch": 0.65,
            "step": 185000
        },
        {
            "loss": 4.0311,
            "learning_rate": 1.74710299791185e-05,
            "epoch": 0.65,
            "step": 186000
        },
        {
            "loss": 3.9922,
            "learning_rate": 1.7296143043522365e-05,
            "epoch": 0.65,
            "step": 187000
        },
        {
            "loss": 4.0322,
            "learning_rate": 1.7121256107926225e-05,
            "epoch": 0.66,
            "step": 188000
        },
        {
            "loss": 3.9745,
            "learning_rate": 1.694636917233009e-05,
            "epoch": 0.66,
            "step": 189000
        },
        {
            "loss": 3.9896,
            "learning_rate": 1.6771482236733953e-05,
            "epoch": 0.66,
            "step": 190000
        },
        {
            "loss": 3.9614,
            "learning_rate": 1.6596595301137817e-05,
            "epoch": 0.67,
            "step": 191000
        },
        {
            "loss": 3.9778,
            "learning_rate": 1.6421708365541677e-05,
            "epoch": 0.67,
            "step": 192000
        },
        {
            "loss": 4.0067,
            "learning_rate": 1.624682142994554e-05,
            "epoch": 0.68,
            "step": 193000
        },
        {
            "loss": 3.9811,
            "learning_rate": 1.60719344943494e-05,
            "epoch": 0.68,
            "step": 194000
        },
        {
            "loss": 3.9817,
            "learning_rate": 1.589704755875327e-05,
            "epoch": 0.68,
            "step": 195000
        },
        {
            "loss": 3.9899,
            "learning_rate": 1.572216062315713e-05,
            "epoch": 0.69,
            "step": 196000
        },
        {
            "loss": 3.9726,
            "learning_rate": 1.5547273687560993e-05,
            "epoch": 0.69,
            "step": 197000
        },
        {
            "loss": 3.9676,
            "learning_rate": 1.5372386751964856e-05,
            "epoch": 0.69,
            "step": 198000
        },
        {
            "loss": 3.9578,
            "learning_rate": 1.5197499816368718e-05,
            "epoch": 0.7,
            "step": 199000
        },
        {
            "loss": 3.9675,
            "learning_rate": 1.5022612880772582e-05,
            "epoch": 0.7,
            "step": 200000
        },
        {
            "loss": 3.9848,
            "learning_rate": 1.4847725945176444e-05,
            "epoch": 0.7,
            "step": 201000
        },
        {
            "loss": 3.9758,
            "learning_rate": 1.4672839009580308e-05,
            "epoch": 0.71,
            "step": 202000
        },
        {
            "loss": 3.9408,
            "learning_rate": 1.449795207398417e-05,
            "epoch": 0.71,
            "step": 203000
        },
        {
            "loss": 3.9644,
            "learning_rate": 1.4323065138388034e-05,
            "epoch": 0.71,
            "step": 204000
        },
        {
            "loss": 3.9432,
            "learning_rate": 1.4148178202791896e-05,
            "epoch": 0.72,
            "step": 205000
        },
        {
            "loss": 3.9614,
            "learning_rate": 1.397329126719576e-05,
            "epoch": 0.72,
            "step": 206000
        },
        {
            "loss": 3.9261,
            "learning_rate": 1.379840433159962e-05,
            "epoch": 0.72,
            "step": 207000
        },
        {
            "loss": 3.9448,
            "learning_rate": 1.3623517396003486e-05,
            "epoch": 0.73,
            "step": 208000
        },
        {
            "loss": 3.9245,
            "learning_rate": 1.3448630460407346e-05,
            "epoch": 0.73,
            "step": 209000
        },
        {
            "loss": 3.9281,
            "learning_rate": 1.3273743524811211e-05,
            "epoch": 0.73,
            "step": 210000
        },
        {
            "loss": 3.8966,
            "learning_rate": 1.3098856589215072e-05,
            "epoch": 0.74,
            "step": 211000
        },
        {
            "loss": 3.9112,
            "learning_rate": 1.2923969653618936e-05,
            "epoch": 0.74,
            "step": 212000
        },
        {
            "loss": 3.9111,
            "learning_rate": 1.2749082718022798e-05,
            "epoch": 0.75,
            "step": 213000
        },
        {
            "loss": 3.9219,
            "learning_rate": 1.2574195782426661e-05,
            "epoch": 0.75,
            "step": 214000
        },
        {
            "loss": 3.8997,
            "learning_rate": 1.2399308846830525e-05,
            "epoch": 0.75,
            "step": 215000
        },
        {
            "loss": 3.9156,
            "learning_rate": 1.2224421911234387e-05,
            "epoch": 0.76,
            "step": 216000
        },
        {
            "loss": 3.9277,
            "learning_rate": 1.2049534975638251e-05,
            "epoch": 0.76,
            "step": 217000
        },
        {
            "loss": 3.9025,
            "learning_rate": 1.1874648040042113e-05,
            "epoch": 0.76,
            "step": 218000
        },
        {
            "loss": 3.9059,
            "learning_rate": 1.1699761104445977e-05,
            "epoch": 0.77,
            "step": 219000
        },
        {
            "loss": 3.9157,
            "learning_rate": 1.1524874168849839e-05,
            "epoch": 0.77,
            "step": 220000
        },
        {
            "loss": 3.922,
            "learning_rate": 1.1349987233253701e-05,
            "epoch": 0.77,
            "step": 221000
        },
        {
            "loss": 3.9099,
            "learning_rate": 1.1175100297657565e-05,
            "epoch": 0.78,
            "step": 222000
        },
        {
            "loss": 3.9172,
            "learning_rate": 1.1000213362061427e-05,
            "epoch": 0.78,
            "step": 223000
        },
        {
            "loss": 3.8868,
            "learning_rate": 1.082532642646529e-05,
            "epoch": 0.78,
            "step": 224000
        },
        {
            "loss": 3.9115,
            "learning_rate": 1.0650439490869153e-05,
            "epoch": 0.79,
            "step": 225000
        },
        {
            "loss": 3.9346,
            "learning_rate": 1.0475552555273017e-05,
            "epoch": 0.79,
            "step": 226000
        },
        {
            "loss": 3.8815,
            "learning_rate": 1.0300665619676879e-05,
            "epoch": 0.79,
            "step": 227000
        },
        {
            "loss": 3.8803,
            "learning_rate": 1.0125778684080742e-05,
            "epoch": 0.8,
            "step": 228000
        },
        {
            "loss": 3.9052,
            "learning_rate": 9.950891748484605e-06,
            "epoch": 0.8,
            "step": 229000
        },
        {
            "loss": 3.864,
            "learning_rate": 9.776004812888468e-06,
            "epoch": 0.8,
            "step": 230000
        },
        {
            "loss": 3.8708,
            "learning_rate": 9.601117877292332e-06,
            "epoch": 0.81,
            "step": 231000
        },
        {
            "loss": 3.8767,
            "learning_rate": 9.426230941696194e-06,
            "epoch": 0.81,
            "step": 232000
        },
        {
            "loss": 3.8763,
            "learning_rate": 9.251344006100058e-06,
            "epoch": 0.81,
            "step": 233000
        },
        {
            "loss": 3.8746,
            "learning_rate": 9.07645707050392e-06,
            "epoch": 0.82,
            "step": 234000
        },
        {
            "loss": 3.8511,
            "learning_rate": 8.901570134907784e-06,
            "epoch": 0.82,
            "step": 235000
        },
        {
            "loss": 3.8583,
            "learning_rate": 8.726683199311646e-06,
            "epoch": 0.83,
            "step": 236000
        },
        {
            "loss": 3.8758,
            "learning_rate": 8.551796263715508e-06,
            "epoch": 0.83,
            "step": 237000
        },
        {
            "loss": 3.8335,
            "learning_rate": 8.376909328119372e-06,
            "epoch": 0.83,
            "step": 238000
        },
        {
            "loss": 3.8597,
            "learning_rate": 8.202022392523234e-06,
            "epoch": 0.84,
            "step": 239000
        },
        {
            "loss": 3.8756,
            "learning_rate": 8.027135456927098e-06,
            "epoch": 0.84,
            "step": 240000
        },
        {
            "loss": 3.8386,
            "learning_rate": 7.85224852133096e-06,
            "epoch": 0.84,
            "step": 241000
        },
        {
            "loss": 3.8742,
            "learning_rate": 7.677361585734823e-06,
            "epoch": 0.85,
            "step": 242000
        },
        {
            "loss": 3.8423,
            "learning_rate": 7.5024746501386855e-06,
            "epoch": 0.85,
            "step": 243000
        },
        {
            "loss": 3.8334,
            "learning_rate": 7.327587714542548e-06,
            "epoch": 0.85,
            "step": 244000
        },
        {
            "loss": 3.8144,
            "learning_rate": 7.152700778946411e-06,
            "epoch": 0.86,
            "step": 245000
        },
        {
            "loss": 3.8303,
            "learning_rate": 6.977813843350274e-06,
            "epoch": 0.86,
            "step": 246000
        },
        {
            "loss": 3.8377,
            "learning_rate": 6.802926907754137e-06,
            "epoch": 0.86,
            "step": 247000
        },
        {
            "loss": 3.8348,
            "learning_rate": 6.628039972158e-06,
            "epoch": 0.87,
            "step": 248000
        },
        {
            "loss": 3.8426,
            "learning_rate": 6.453153036561862e-06,
            "epoch": 0.87,
            "step": 249000
        },
        {
            "loss": 3.8186,
            "learning_rate": 6.278266100965725e-06,
            "epoch": 0.87,
            "step": 250000
        },
        {
            "loss": 3.8651,
            "learning_rate": 6.103379165369589e-06,
            "epoch": 0.88,
            "step": 251000
        },
        {
            "loss": 3.8414,
            "learning_rate": 5.928492229773452e-06,
            "epoch": 0.88,
            "step": 252000
        },
        {
            "loss": 3.8627,
            "learning_rate": 5.753605294177315e-06,
            "epoch": 0.88,
            "step": 253000
        },
        {
            "loss": 3.8219,
            "learning_rate": 5.578718358581178e-06,
            "epoch": 0.89,
            "step": 254000
        },
        {
            "loss": 3.8427,
            "learning_rate": 5.4038314229850405e-06,
            "epoch": 0.89,
            "step": 255000
        },
        {
            "loss": 3.8149,
            "learning_rate": 5.2289444873889035e-06,
            "epoch": 0.9,
            "step": 256000
        },
        {
            "loss": 3.8456,
            "learning_rate": 5.0540575517927655e-06,
            "epoch": 0.9,
            "step": 257000
        },
        {
            "loss": 3.8471,
            "learning_rate": 4.879170616196629e-06,
            "epoch": 0.9,
            "step": 258000
        },
        {
            "loss": 3.8235,
            "learning_rate": 4.704283680600492e-06,
            "epoch": 0.91,
            "step": 259000
        },
        {
            "loss": 3.8386,
            "learning_rate": 4.529396745004355e-06,
            "epoch": 0.91,
            "step": 260000
        },
        {
            "loss": 3.811,
            "learning_rate": 4.354509809408218e-06,
            "epoch": 0.91,
            "step": 261000
        },
        {
            "loss": 3.8344,
            "learning_rate": 4.179622873812081e-06,
            "epoch": 0.92,
            "step": 262000
        },
        {
            "loss": 3.8491,
            "learning_rate": 4.004735938215944e-06,
            "epoch": 0.92,
            "step": 263000
        },
        {
            "loss": 3.8282,
            "learning_rate": 3.829849002619806e-06,
            "epoch": 0.92,
            "step": 264000
        },
        {
            "loss": 3.8007,
            "learning_rate": 3.6549620670236694e-06,
            "epoch": 0.93,
            "step": 265000
        },
        {
            "loss": 3.7999,
            "learning_rate": 3.480075131427532e-06,
            "epoch": 0.93,
            "step": 266000
        },
        {
            "loss": 3.8015,
            "learning_rate": 3.305188195831395e-06,
            "epoch": 0.93,
            "step": 267000
        },
        {
            "loss": 3.8157,
            "learning_rate": 3.1303012602352577e-06,
            "epoch": 0.94,
            "step": 268000
        },
        {
            "loss": 3.8052,
            "learning_rate": 2.955414324639121e-06,
            "epoch": 0.94,
            "step": 269000
        },
        {
            "loss": 3.8111,
            "learning_rate": 2.7805273890429836e-06,
            "epoch": 0.94,
            "step": 270000
        },
        {
            "loss": 3.786,
            "learning_rate": 2.605640453446847e-06,
            "epoch": 0.95,
            "step": 271000
        },
        {
            "loss": 3.8043,
            "learning_rate": 2.43075351785071e-06,
            "epoch": 0.95,
            "step": 272000
        },
        {
            "loss": 3.805,
            "learning_rate": 2.2558665822545728e-06,
            "epoch": 0.95,
            "step": 273000
        },
        {
            "loss": 3.8209,
            "learning_rate": 2.0809796466584353e-06,
            "epoch": 0.96,
            "step": 274000
        },
        {
            "loss": 3.7982,
            "learning_rate": 1.9060927110622982e-06,
            "epoch": 0.96,
            "step": 275000
        },
        {
            "loss": 3.8076,
            "learning_rate": 1.7312057754661611e-06,
            "epoch": 0.97,
            "step": 276000
        },
        {
            "loss": 3.8015,
            "learning_rate": 1.556318839870024e-06,
            "epoch": 0.97,
            "step": 277000
        },
        {
            "loss": 3.8046,
            "learning_rate": 1.381431904273887e-06,
            "epoch": 0.97,
            "step": 278000
        },
        {
            "loss": 3.7832,
            "learning_rate": 1.2065449686777499e-06,
            "epoch": 0.98,
            "step": 279000
        },
        {
            "loss": 3.8004,
            "learning_rate": 1.0316580330816128e-06,
            "epoch": 0.98,
            "step": 280000
        },
        {
            "loss": 3.7913,
            "learning_rate": 8.567710974854757e-07,
            "epoch": 0.98,
            "step": 281000
        },
        {
            "loss": 3.8056,
            "learning_rate": 6.818841618893386e-07,
            "epoch": 0.99,
            "step": 282000
        },
        {
            "loss": 3.8105,
            "learning_rate": 5.069972262932015e-07,
            "epoch": 0.99,
            "step": 283000
        },
        {
            "loss": 3.7895,
            "learning_rate": 3.3211029069706435e-07,
            "epoch": 0.99,
            "step": 284000
        },
        {
            "loss": 3.7783,
            "learning_rate": 1.5722335510092725e-07,
            "epoch": 1.0,
            "step": 285000
        },
        {
            "train_runtime": 33378.4977,
            "train_samples_per_second": 137.045,
            "train_steps_per_second": 8.565,
            "total_flos": 1.5221554276778035e+17,
            "train_loss": 4.4419994452484515,
            "epoch": 1.0,
            "step": 285899
        }
    ],
    "weight_kurtosis": {
        "weight_kurtosis": {
            "roberta.embeddings.word_embeddings.weight": 2.994751453399658,
            "roberta.embeddings.position_embeddings.weight": 0.29543423652648926,
            "roberta.embeddings.token_type_embeddings.weight": 5.0946855545043945,
            "roberta.embeddings.LayerNorm.weight": 6.580493927001953,
            "roberta.embeddings.LayerNorm.bias": 0.2249758243560791,
            "roberta.encoder.layer.0.attention.self.query.weight": 0.30980420112609863,
            "roberta.encoder.layer.0.attention.self.query.bias": 0.11952900886535645,
            "roberta.encoder.layer.0.attention.self.key.weight": 0.22936272621154785,
            "roberta.encoder.layer.0.attention.self.key.bias": -0.7705178260803223,
            "roberta.encoder.layer.0.attention.self.value.weight": 0.0538477897644043,
            "roberta.encoder.layer.0.attention.self.value.bias": 1.6697821617126465,
            "roberta.encoder.layer.0.attention.output.dense.weight": 0.07195329666137695,
            "roberta.encoder.layer.0.attention.output.dense.bias": 3.332885265350342,
            "roberta.encoder.layer.0.attention.output.LayerNorm.weight": 7.444868087768555,
            "roberta.encoder.layer.0.attention.output.LayerNorm.bias": 6.358242988586426,
            "roberta.encoder.layer.0.intermediate.dense.weight": 0.05005049705505371,
            "roberta.encoder.layer.0.intermediate.dense.bias": 0.43625593185424805,
            "roberta.encoder.layer.0.output.dense.weight": 0.11245059967041016,
            "roberta.encoder.layer.0.output.dense.bias": 8.347895622253418,
            "roberta.encoder.layer.0.output.LayerNorm.weight": 10.57873821258545,
            "roberta.encoder.layer.0.output.LayerNorm.bias": 1.5265164375305176,
            "roberta.encoder.layer.1.attention.self.query.weight": 0.25396251678466797,
            "roberta.encoder.layer.1.attention.self.query.bias": 2.4036498069763184,
            "roberta.encoder.layer.1.attention.self.key.weight": 0.2314610481262207,
            "roberta.encoder.layer.1.attention.self.key.bias": 0.38983893394470215,
            "roberta.encoder.layer.1.attention.self.value.weight": 0.02302694320678711,
            "roberta.encoder.layer.1.attention.self.value.bias": 1.7037653923034668,
            "roberta.encoder.layer.1.attention.output.dense.weight": 0.032953739166259766,
            "roberta.encoder.layer.1.attention.output.dense.bias": 1.5510025024414062,
            "roberta.encoder.layer.1.attention.output.LayerNorm.weight": 6.877326011657715,
            "roberta.encoder.layer.1.attention.output.LayerNorm.bias": 2.5455641746520996,
            "roberta.encoder.layer.1.intermediate.dense.weight": 0.017797231674194336,
            "roberta.encoder.layer.1.intermediate.dense.bias": 0.011824607849121094,
            "roberta.encoder.layer.1.output.dense.weight": 0.02545762062072754,
            "roberta.encoder.layer.1.output.dense.bias": 1.0304031372070312,
            "roberta.encoder.layer.1.output.LayerNorm.weight": 11.797051429748535,
            "roberta.encoder.layer.1.output.LayerNorm.bias": 0.9527339935302734,
            "roberta.encoder.layer.2.attention.self.query.weight": 0.028247833251953125,
            "roberta.encoder.layer.2.attention.self.query.bias": 0.15413379669189453,
            "roberta.encoder.layer.2.attention.self.key.weight": 0.015514135360717773,
            "roberta.encoder.layer.2.attention.self.key.bias": -0.5362033843994141,
            "roberta.encoder.layer.2.attention.self.value.weight": 0.035219430923461914,
            "roberta.encoder.layer.2.attention.self.value.bias": 0.33124852180480957,
            "roberta.encoder.layer.2.attention.output.dense.weight": 0.024068355560302734,
            "roberta.encoder.layer.2.attention.output.dense.bias": 3.1290926933288574,
            "roberta.encoder.layer.2.attention.output.LayerNorm.weight": 7.23445987701416,
            "roberta.encoder.layer.2.attention.output.LayerNorm.bias": 2.2474656105041504,
            "roberta.encoder.layer.2.intermediate.dense.weight": 0.021319150924682617,
            "roberta.encoder.layer.2.intermediate.dense.bias": -0.0790860652923584,
            "roberta.encoder.layer.2.output.dense.weight": 0.014698505401611328,
            "roberta.encoder.layer.2.output.dense.bias": 2.01298189163208,
            "roberta.encoder.layer.2.output.LayerNorm.weight": 7.392374038696289,
            "roberta.encoder.layer.2.output.LayerNorm.bias": 0.6985523700714111,
            "roberta.encoder.layer.3.attention.self.query.weight": 0.017101764678955078,
            "roberta.encoder.layer.3.attention.self.query.bias": 0.23810815811157227,
            "roberta.encoder.layer.3.attention.self.key.weight": 0.02529764175415039,
            "roberta.encoder.layer.3.attention.self.key.bias": -0.5644657611846924,
            "roberta.encoder.layer.3.attention.self.value.weight": 0.01488041877746582,
            "roberta.encoder.layer.3.attention.self.value.bias": 0.3195672035217285,
            "roberta.encoder.layer.3.attention.output.dense.weight": 0.01749444007873535,
            "roberta.encoder.layer.3.attention.output.dense.bias": 1.0255208015441895,
            "roberta.encoder.layer.3.attention.output.LayerNorm.weight": 3.7651047706604004,
            "roberta.encoder.layer.3.attention.output.LayerNorm.bias": 0.7596395015716553,
            "roberta.encoder.layer.3.intermediate.dense.weight": 0.01335906982421875,
            "roberta.encoder.layer.3.intermediate.dense.bias": -0.27976393699645996,
            "roberta.encoder.layer.3.output.dense.weight": 0.01314091682434082,
            "roberta.encoder.layer.3.output.dense.bias": 0.7999098300933838,
            "roberta.encoder.layer.3.output.LayerNorm.weight": 1.6930131912231445,
            "roberta.encoder.layer.3.output.LayerNorm.bias": 0.22205424308776855,
            "roberta.encoder.layer.4.attention.self.query.weight": 0.007347583770751953,
            "roberta.encoder.layer.4.attention.self.query.bias": -0.2792856693267822,
            "roberta.encoder.layer.4.attention.self.key.weight": 0.0016889572143554688,
            "roberta.encoder.layer.4.attention.self.key.bias": -0.4087231159210205,
            "roberta.encoder.layer.4.attention.self.value.weight": 0.013862848281860352,
            "roberta.encoder.layer.4.attention.self.value.bias": 0.245131254196167,
            "roberta.encoder.layer.4.attention.output.dense.weight": 0.01205301284790039,
            "roberta.encoder.layer.4.attention.output.dense.bias": -0.14264345169067383,
            "roberta.encoder.layer.4.attention.output.LayerNorm.weight": 0.8847577571868896,
            "roberta.encoder.layer.4.attention.output.LayerNorm.bias": -0.21049904823303223,
            "roberta.encoder.layer.4.intermediate.dense.weight": 0.012718677520751953,
            "roberta.encoder.layer.4.intermediate.dense.bias": -0.608734130859375,
            "roberta.encoder.layer.4.output.dense.weight": 0.0123748779296875,
            "roberta.encoder.layer.4.output.dense.bias": -0.5427608489990234,
            "roberta.encoder.layer.4.output.LayerNorm.weight": 0.09586095809936523,
            "roberta.encoder.layer.4.output.LayerNorm.bias": -0.4714531898498535,
            "roberta.encoder.layer.5.attention.self.query.weight": 0.010294198989868164,
            "roberta.encoder.layer.5.attention.self.query.bias": -0.755040168762207,
            "roberta.encoder.layer.5.attention.self.key.weight": 0.013532638549804688,
            "roberta.encoder.layer.5.attention.self.key.bias": -0.4050893783569336,
            "roberta.encoder.layer.5.attention.self.value.weight": 0.09125185012817383,
            "roberta.encoder.layer.5.attention.self.value.bias": -0.01744365692138672,
            "roberta.encoder.layer.5.attention.output.dense.weight": 0.0829617977142334,
            "roberta.encoder.layer.5.attention.output.dense.bias": -0.4068295955657959,
            "roberta.encoder.layer.5.attention.output.LayerNorm.weight": 0.4244530200958252,
            "roberta.encoder.layer.5.attention.output.LayerNorm.bias": -0.4548029899597168,
            "roberta.encoder.layer.5.intermediate.dense.weight": 0.019262313842773438,
            "roberta.encoder.layer.5.intermediate.dense.bias": -0.01605367660522461,
            "roberta.encoder.layer.5.output.dense.weight": 0.013623952865600586,
            "roberta.encoder.layer.5.output.dense.bias": -0.6748402118682861,
            "roberta.encoder.layer.5.output.LayerNorm.weight": 0.46192407608032227,
            "roberta.encoder.layer.5.output.LayerNorm.bias": -0.4783360958099365,
            "lm_head.bias": 0.510704517364502,
            "lm_head.dense.weight": 5.426597595214844,
            "lm_head.dense.bias": 6.717933654785156,
            "lm_head.layer_norm.weight": 8.871054649353027,
            "lm_head.layer_norm.bias": 7.073502540588379
        },
        "weight_avg_attn_kurt": {
            "attention.output.dense.weight": {
                "avg": 0.040247440338134766,
                "std": 0.02725607967219531
            },
            "attention.output.dense.bias": {
                "avg": 1.4148380359013875,
                "std": 1.4452165016328573
            },
            "attention.output.LayerNorm.weight": {
                "avg": 4.438494920730591,
                "std": 2.9438815433635455
            },
            "attention.output.LayerNorm.bias": {
                "avg": 1.874268372853597,
                "std": 2.298882653233783
            }
        }
    },
    "activation_kurtosis": {
        "activation_kurtosis": {
            "roberta.embeddings.word_embeddings": 9.896329292936297,
            "roberta.embeddings.token_type_embeddings": 3.230524058970378,
            "roberta.embeddings.position_embeddings": 47.78332843316941,
            "roberta.embeddings.LayerNorm": 4.812399723743918,
            "roberta.embeddings.dropout": 5.663566607381277,
            "roberta.embeddings": 5.663566607381277,
            "roberta.encoder.layer.0.attention.self.query": 0.3677183154397014,
            "roberta.encoder.layer.0.attention.self.key": 0.7427101769160626,
            "roberta.encoder.layer.0.attention.self.value": 0.8101650498285483,
            "roberta.encoder.layer.0.attention.self.dropout": 945.2684580681353,
            "roberta.encoder.layer.0.attention.self": 30.821360170729,
            "roberta.encoder.layer.0.attention.output.dense": 1.909643238467061,
            "roberta.encoder.layer.0.attention.output.dropout": 2.458140648193966,
            "roberta.encoder.layer.0.attention.output.LayerNorm": 3.7964698104256613,
            "roberta.encoder.layer.0.attention.output": 3.7964698104256613,
            "roberta.encoder.layer.0.attention": 3.7686709543601085,
            "roberta.encoder.layer.0.intermediate.dense": 0.5834961377039745,
            "roberta.encoder.layer.0.intermediate.intermediate_act_fn": 19.064328760524006,
            "roberta.encoder.layer.0.intermediate": 19.064328760524006,
            "roberta.encoder.layer.0.output.dense": 26.04701482870183,
            "roberta.encoder.layer.0.output.dropout": 29.161667697865326,
            "roberta.encoder.layer.0.output.LayerNorm": 1.539061255291253,
            "roberta.encoder.layer.0.output": 1.539061255291253,
            "roberta.encoder.layer.0": 1.535889293769512,
            "roberta.encoder.layer.1.attention.self.query": 0.4358715010636596,
            "roberta.encoder.layer.1.attention.self.key": 0.37870883254235926,
            "roberta.encoder.layer.1.attention.self.value": 0.4466720278855998,
            "roberta.encoder.layer.1.attention.self.dropout": 275.011414974186,
            "roberta.encoder.layer.1.attention.self": 3.7746157087518024,
            "roberta.encoder.layer.1.attention.output.dense": 1.3997576830999523,
            "roberta.encoder.layer.1.attention.output.dropout": 1.8884709875110166,
            "roberta.encoder.layer.1.attention.output.LayerNorm": 0.6892215751923763,
            "roberta.encoder.layer.1.attention.output": 0.6892215751923763,
            "roberta.encoder.layer.1.attention": 0.6887382225996546,
            "roberta.encoder.layer.1.intermediate.dense": 0.4134170594130508,
            "roberta.encoder.layer.1.intermediate.intermediate_act_fn": 51.113943788163134,
            "roberta.encoder.layer.1.intermediate": 51.113943788163134,
            "roberta.encoder.layer.1.output.dense": 10.692468551263863,
            "roberta.encoder.layer.1.output.dropout": 12.20755562021064,
            "roberta.encoder.layer.1.output.LayerNorm": 0.3546136550803609,
            "roberta.encoder.layer.1.output": 0.3546136550803609,
            "roberta.encoder.layer.1": 0.35453322017379907,
            "roberta.encoder.layer.2.attention.self.query": 0.15712686268350332,
            "roberta.encoder.layer.2.attention.self.key": 0.11569261152413311,
            "roberta.encoder.layer.2.attention.self.value": 0.29282107188194334,
            "roberta.encoder.layer.2.attention.self.dropout": 230.4686712735533,
            "roberta.encoder.layer.2.attention.self": 3.7229114317682908,
            "roberta.encoder.layer.2.attention.output.dense": 0.44601993133033185,
            "roberta.encoder.layer.2.attention.output.dropout": 0.8287265421631905,
            "roberta.encoder.layer.2.attention.output.LayerNorm": 0.3216775273166061,
            "roberta.encoder.layer.2.attention.output": 0.3216775273166061,
            "roberta.encoder.layer.2.attention": 0.3216724935543665,
            "roberta.encoder.layer.2.intermediate.dense": 0.2845302469861324,
            "roberta.encoder.layer.2.intermediate.intermediate_act_fn": 26.757162890252236,
            "roberta.encoder.layer.2.intermediate": 26.757162890252236,
            "roberta.encoder.layer.2.output.dense": 11.409756805425472,
            "roberta.encoder.layer.2.output.dropout": 13.003343839826996,
            "roberta.encoder.layer.2.output.LayerNorm": 0.17607430356440668,
            "roberta.encoder.layer.2.output": 0.17607430356440668,
            "roberta.encoder.layer.2": 0.1760218963506984,
            "roberta.encoder.layer.3.attention.self.query": 0.17557824150285717,
            "roberta.encoder.layer.3.attention.self.key": 0.2704073677740708,
            "roberta.encoder.layer.3.attention.self.value": 0.23604034822168082,
            "roberta.encoder.layer.3.attention.self.dropout": 272.43340302120924,
            "roberta.encoder.layer.3.attention.self": 5.111669747209849,
            "roberta.encoder.layer.3.attention.output.dense": 0.5653903641897683,
            "roberta.encoder.layer.3.attention.output.dropout": 0.9613417149724062,
            "roberta.encoder.layer.3.attention.output.LayerNorm": 0.21197336630777389,
            "roberta.encoder.layer.3.attention.output": 0.21197336630777389,
            "roberta.encoder.layer.3.attention": 0.2118802058893966,
            "roberta.encoder.layer.3.intermediate.dense": 0.21186470126895662,
            "roberta.encoder.layer.3.intermediate.intermediate_act_fn": 28.03877290843873,
            "roberta.encoder.layer.3.intermediate": 28.03877290843873,
            "roberta.encoder.layer.3.output.dense": 7.263691733548265,
            "roberta.encoder.layer.3.output.dropout": 8.402249322498493,
            "roberta.encoder.layer.3.output.LayerNorm": 0.18684679524652545,
            "roberta.encoder.layer.3.output": 0.18684679524652545,
            "roberta.encoder.layer.3": 0.18667312037701803,
            "roberta.encoder.layer.4.attention.self.query": 0.026807127534891024,
            "roberta.encoder.layer.4.attention.self.key": -0.2416277435607782,
            "roberta.encoder.layer.4.attention.self.value": 0.12810282300386105,
            "roberta.encoder.layer.4.attention.self.dropout": 562.8845145907142,
            "roberta.encoder.layer.4.attention.self": 11.093535568438762,
            "roberta.encoder.layer.4.attention.output.dense": 2.2545137504179946,
            "roberta.encoder.layer.4.attention.output.dropout": 2.837975431746816,
            "roberta.encoder.layer.4.attention.output.LayerNorm": 0.20515749971392885,
            "roberta.encoder.layer.4.attention.output": 0.20515749971392885,
            "roberta.encoder.layer.4.attention": 0.20498541729508385,
            "roberta.encoder.layer.4.intermediate.dense": 0.09370916770937411,
            "roberta.encoder.layer.4.intermediate.intermediate_act_fn": 30.90471533282149,
            "roberta.encoder.layer.4.intermediate": 30.90471533282149,
            "roberta.encoder.layer.4.output.dense": 0.249157655681456,
            "roberta.encoder.layer.4.output.dropout": 0.6100219058652103,
            "roberta.encoder.layer.4.output.LayerNorm": 0.17378902734732948,
            "roberta.encoder.layer.4.output": 0.17378902734732948,
            "roberta.encoder.layer.4": 0.17357483550125136,
            "roberta.encoder.layer.5.attention.self.query": -0.38388705080580265,
            "roberta.encoder.layer.5.attention.self.key": -0.5282421158721949,
            "roberta.encoder.layer.5.attention.self.value": 0.16114689508990368,
            "roberta.encoder.layer.5.attention.self.dropout": 1777.4147961282051,
            "roberta.encoder.layer.5.attention.self": 29.92871993445555,
            "roberta.encoder.layer.5.attention.output.dense": 5.183059765783675,
            "roberta.encoder.layer.5.attention.output.dropout": 6.091017570353226,
            "roberta.encoder.layer.5.attention.output.LayerNorm": 0.18909226476476806,
            "roberta.encoder.layer.5.attention.output": 0.18909226476476806,
            "roberta.encoder.layer.5.attention": 0.1889093974177536,
            "roberta.encoder.layer.5.intermediate.dense": 0.07869787923445755,
            "roberta.encoder.layer.5.intermediate.intermediate_act_fn": 42.99873402555353,
            "roberta.encoder.layer.5.intermediate": 42.99873402555353,
            "roberta.encoder.layer.5.output.dense": 0.6463521750422734,
            "roberta.encoder.layer.5.output.dropout": 1.0512453753996394,
            "roberta.encoder.layer.5.output.LayerNorm": 0.14885923264514042,
            "roberta.encoder.layer.5.output": 0.14885923264514042,
            "roberta.encoder.layer.5": 0.14846047301385232,
            "roberta.encoder": 0.14846047301385232,
            "roberta": 0.14846047301385232,
            "lm_head.dense": 5.873651716193692,
            "lm_head.layer_norm": 0.6972422441472085,
            "lm_head.decoder": 1.248733819378869,
            "lm_head": 1.248733819378869,
            "": NaN
        },
        "activation_avg_attn_kurt": {
            "attention.output.dense": {
                "avg": 1.9597307888814637,
                "std": 1.5826313062877497
            },
            "attention.output.dropout": {
                "avg": 2.510945482490104,
                "std": 1.7580889240371023
            },
            "attention.output.LayerNorm": {
                "avg": 0.9022653406201857,
                "std": 1.3057544151284393
            },
            "attention.output": {
                "avg": 0.9022653406201857,
                "std": 1.3057544151284393
            }
        }
    }
}